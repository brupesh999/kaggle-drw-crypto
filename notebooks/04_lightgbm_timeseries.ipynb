{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0364d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9784f1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/brupesh/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbrupeshmit\u001b[0m (\u001b[33mbrupeshmit-massachusetts-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"WANDB_API_KEY\"] = os.getenv(\"WANDB_API_KEY\")\n",
    "os.environ[\"WANDB_DIR\"] = \"../data/wandb_logs\"\n",
    "wandb.login(key=os.environ[\"WANDB_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "916c8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../data/train_clean_v2.parquet\")\n",
    "test = pd.read_parquet(\"../data/test_clean_v2.parquet\")\n",
    "target_col = \"label\"\n",
    "y = train[target_col]\n",
    "X = train.drop(columns=[target_col])\n",
    "\n",
    "test_ids = test.iloc[:, 0]\n",
    "test = test.drop(columns=[test.columns[0]])\n",
    "\n",
    "feature_df = pd.read_csv(\"../data/resources/lgbm_feature_importance.csv\")\n",
    "top_features = feature_df.sort_values(by=\"importance\", ascending=False)[\"feature\"].iloc[:400].tolist()\n",
    "X = X[top_features]\n",
    "test = test[top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa17f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../data/wandb_logs/wandb/run-20250814_224302-16jlstal</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/brupeshmit-massachusetts-institute-of-technology/kaggle-drw-crypto/runs/16jlstal' target=\"_blank\">lightgbm_default_with_regularization</a></strong> to <a href='https://wandb.ai/brupeshmit-massachusetts-institute-of-technology/kaggle-drw-crypto' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/brupeshmit-massachusetts-institute-of-technology/kaggle-drw-crypto' target=\"_blank\">https://wandb.ai/brupeshmit-massachusetts-institute-of-technology/kaggle-drw-crypto</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/brupeshmit-massachusetts-institute-of-technology/kaggle-drw-crypto/runs/16jlstal' target=\"_blank\">https://wandb.ai/brupeshmit-massachusetts-institute-of-technology/kaggle-drw-crypto/runs/16jlstal</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"device\": \"gpu\",\n",
    "    \"gpu_platform_id\": 0,\n",
    "    \"gpu_device_id\": 0,\n",
    "    \"verbosity\": -1\n",
    "}\n",
    "\n",
    "params.update({\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 63,\n",
    "    \"max_depth\": 6,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"lambda_l2\": 1.0,\n",
    "    \"lambda_l1\": 0.1,\n",
    "})\n",
    "\n",
    "wandb.init(\n",
    "    project=\"kaggle-drw-crypto\",\n",
    "    name=\"lightgbm_default_with_regularization\",\n",
    "    config=params\n",
    ")\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "rmse_scores = []\n",
    "overfit_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25640aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 0.999795\n",
      "[200]\tvalid_0's rmse: 1.01578\n",
      "[300]\tvalid_0's rmse: 1.03035\n",
      "[400]\tvalid_0's rmse: 1.04147\n",
      "[500]\tvalid_0's rmse: 1.04975\n",
      "[600]\tvalid_0's rmse: 1.05612\n",
      "[700]\tvalid_0's rmse: 1.06176\n",
      "[800]\tvalid_0's rmse: 1.06596\n",
      "[900]\tvalid_0's rmse: 1.06959\n",
      "[1000]\tvalid_0's rmse: 1.07384\n",
      "Fold 0 Pearson correlation: 0.0580\n",
      "[100]\tvalid_0's rmse: 1.02459\n",
      "[200]\tvalid_0's rmse: 1.0409\n",
      "[300]\tvalid_0's rmse: 1.05579\n",
      "[400]\tvalid_0's rmse: 1.06725\n",
      "[500]\tvalid_0's rmse: 1.07702\n",
      "[600]\tvalid_0's rmse: 1.08263\n",
      "[700]\tvalid_0's rmse: 1.08815\n",
      "[800]\tvalid_0's rmse: 1.09398\n",
      "[900]\tvalid_0's rmse: 1.09839\n",
      "[1000]\tvalid_0's rmse: 1.10166\n",
      "Fold 1 Pearson correlation: 0.0496\n",
      "[100]\tvalid_0's rmse: 1.02854\n",
      "[200]\tvalid_0's rmse: 1.05699\n",
      "[300]\tvalid_0's rmse: 1.08161\n",
      "[400]\tvalid_0's rmse: 1.09273\n",
      "[500]\tvalid_0's rmse: 1.10366\n",
      "[600]\tvalid_0's rmse: 1.11343\n",
      "[700]\tvalid_0's rmse: 1.12562\n",
      "[800]\tvalid_0's rmse: 1.13426\n",
      "[900]\tvalid_0's rmse: 1.13972\n",
      "[1000]\tvalid_0's rmse: 1.14481\n",
      "Fold 2 Pearson correlation: 0.0396\n",
      "[100]\tvalid_0's rmse: 0.990693\n",
      "[200]\tvalid_0's rmse: 1.00213\n",
      "[300]\tvalid_0's rmse: 1.00736\n",
      "[400]\tvalid_0's rmse: 1.01666\n",
      "[500]\tvalid_0's rmse: 1.02369\n",
      "[600]\tvalid_0's rmse: 1.03186\n",
      "[700]\tvalid_0's rmse: 1.03661\n",
      "[800]\tvalid_0's rmse: 1.04699\n",
      "[900]\tvalid_0's rmse: 1.05198\n",
      "[1000]\tvalid_0's rmse: 1.0584\n",
      "Fold 3 Pearson correlation: 0.0914\n",
      "[100]\tvalid_0's rmse: 1.0761\n",
      "[200]\tvalid_0's rmse: 1.11141\n",
      "[300]\tvalid_0's rmse: 1.14313\n",
      "[400]\tvalid_0's rmse: 1.16395\n",
      "[500]\tvalid_0's rmse: 1.18256\n",
      "[600]\tvalid_0's rmse: 1.20026\n",
      "[700]\tvalid_0's rmse: 1.21523\n",
      "[800]\tvalid_0's rmse: 1.2251\n",
      "[900]\tvalid_0's rmse: 1.23731\n",
      "[1000]\tvalid_0's rmse: 1.24862\n",
      "Fold 4 Pearson correlation: 0.0164\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dval = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[dval],\n",
    "        # callbacks=[lgb.early_stopping(100), lgb.log_evaluation(100)],\n",
    "        callbacks=[lgb.log_evaluation(100)]\n",
    "    )\n",
    "\n",
    "    preds_val = model.predict(X_val)\n",
    "    preds_train = model.predict(X_train)\n",
    "\n",
    "    try:\n",
    "        pearson_val = pearsonr(y_val, preds_val)[0]\n",
    "    except:\n",
    "        pearson_val = 0.0\n",
    "        \n",
    "    rmse_val = root_mean_squared_error(y_val, preds_val)\n",
    "    rmse_train = root_mean_squared_error(y_train, preds_train)\n",
    "    r2_val = r2_score(y_val, preds_val)\n",
    "\n",
    "    overfit_score = rmse_val - rmse_train\n",
    "\n",
    "    rmse_scores.append(rmse_val)\n",
    "    overfit_scores.append(overfit_score)\n",
    "\n",
    "    wandb.log({\n",
    "        f\"fold_{fold}_rmse\": rmse_val,\n",
    "        f\"fold_{fold}_overfit\": overfit_score,\n",
    "        f\"fold_{fold}_pearson\": pearson_val\n",
    "    })\n",
    "\n",
    "    print(f\"Fold {fold} Pearson correlation: {pearson_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f0f91e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE: 1.125465\n",
      "Average Overfit Score (val - train RMSE): 0.645703\n"
     ]
    }
   ],
   "source": [
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_overfit = np.mean(overfit_scores)\n",
    "\n",
    "wandb.log({\n",
    "    \"avg_rmse\": avg_rmse,\n",
    "    \"avg_overfit\": avg_overfit\n",
    "})\n",
    "\n",
    "print(f\"Average RMSE: {avg_rmse:.6f}\")\n",
    "print(f\"Average Overfit Score (val - train RMSE): {avg_overfit:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39618bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 0.940859\n",
      "[200]\ttraining's rmse: 0.886913\n",
      "[300]\ttraining's rmse: 0.841394\n",
      "[400]\ttraining's rmse: 0.800667\n",
      "[500]\ttraining's rmse: 0.766387\n",
      "[600]\ttraining's rmse: 0.738115\n",
      "[700]\ttraining's rmse: 0.71185\n",
      "[800]\ttraining's rmse: 0.687675\n",
      "[900]\ttraining's rmse: 0.667356\n",
      "[1000]\ttraining's rmse: 0.647941\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_overfit</td><td>▁</td></tr><tr><td>avg_rmse</td><td>▁</td></tr><tr><td>fold_0_overfit</td><td>▁</td></tr><tr><td>fold_0_pearson</td><td>▁</td></tr><tr><td>fold_0_rmse</td><td>▁</td></tr><tr><td>fold_1_overfit</td><td>▁</td></tr><tr><td>fold_1_pearson</td><td>▁</td></tr><tr><td>fold_1_rmse</td><td>▁</td></tr><tr><td>fold_2_overfit</td><td>▁</td></tr><tr><td>fold_2_pearson</td><td>▁</td></tr><tr><td>fold_2_rmse</td><td>▁</td></tr><tr><td>fold_3_overfit</td><td>▁</td></tr><tr><td>fold_3_pearson</td><td>▁</td></tr><tr><td>fold_3_rmse</td><td>▁</td></tr><tr><td>fold_4_overfit</td><td>▁</td></tr><tr><td>fold_4_pearson</td><td>▁</td></tr><tr><td>fold_4_rmse</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_overfit</td><td>0.6457</td></tr><tr><td>avg_rmse</td><td>1.12547</td></tr><tr><td>fold_0_overfit</td><td>0.76184</td></tr><tr><td>fold_0_pearson</td><td>0.05797</td></tr><tr><td>fold_0_rmse</td><td>1.07384</td></tr><tr><td>fold_1_overfit</td><td>0.67498</td></tr><tr><td>fold_1_pearson</td><td>0.04962</td></tr><tr><td>fold_1_rmse</td><td>1.10166</td></tr><tr><td>fold_2_overfit</td><td>0.64814</td></tr><tr><td>fold_2_pearson</td><td>0.03958</td></tr><tr><td>fold_2_rmse</td><td>1.14481</td></tr><tr><td>fold_3_overfit</td><td>0.50355</td></tr><tr><td>fold_3_pearson</td><td>0.09135</td></tr><tr><td>fold_3_rmse</td><td>1.0584</td></tr><tr><td>fold_4_overfit</td><td>0.64</td></tr><tr><td>fold_4_pearson</td><td>0.01636</td></tr><tr><td>fold_4_rmse</td><td>1.24862</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lightgbm_default_with_regularization</strong> at: <a href='https://wandb.ai/brupeshmit-massachusetts-institute-of-technology/kaggle-drw-crypto/runs/16jlstal' target=\"_blank\">https://wandb.ai/brupeshmit-massachusetts-institute-of-technology/kaggle-drw-crypto/runs/16jlstal</a><br> View project at: <a href='https://wandb.ai/brupeshmit-massachusetts-institute-of-technology/kaggle-drw-crypto' target=\"_blank\">https://wandb.ai/brupeshmit-massachusetts-institute-of-technology/kaggle-drw-crypto</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../data/wandb_logs/wandb/run-20250814_224302-16jlstal/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dtrain_full = lgb.Dataset(X, label=y)\n",
    "final_model = lgb.train(\n",
    "    params,\n",
    "    dtrain_full,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[dtrain_full],\n",
    "    callbacks=[lgb.log_evaluation(100)]\n",
    ")\n",
    "\n",
    "final_model.save_model(\"../data/models/lightgbm_default_ts_model.txt\")\n",
    "preds = final_model.predict(test)\n",
    "pd.DataFrame({\"id\": test_ids, \"prediction\": preds}).to_csv(\"../data/preds/lightgbm_default_ts_preds.csv\", index=False)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e14041b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import lightgbm as lgb\n",
    "\n",
    "# def generate_submission(top_n_features: int, model_dir=\"../data\", feature_importance_path=\"lgbm_feature_importance.csv\", test_path=\"../data/test_clean_v2.parquet\"):\n",
    "    \n",
    "#     model_path = f\"{model_dir}/lightgbm_top{top_n_features}_features.txt\"\n",
    "#     model = lgb.Booster(model_file=model_path)\n",
    "\n",
    "#     top_features = feat_importance_df.sort_values(\"importance\", ascending=False).head(top_n_features)[\"feature\"].tolist()\n",
    "    \n",
    "#     preds = model.predict(test_df[top_features], num_iteration=model.best_iteration)\n",
    "\n",
    "#     submission = pd.DataFrame({\n",
    "#         \"ID\": np.arange(1, len(test_df) + 1),  # 1-indexed IDs oops mine were 0-indexed\n",
    "#         \"prediction\": preds\n",
    "#     })\n",
    "\n",
    "#     sub_path = f\"{model_dir}/lightgbm_top{top_n_features}_submission.csv\"\n",
    "#     submission.to_csv(sub_path, index=False)\n",
    "#     print(f\"Saved submission to {sub_path}\")\n",
    "\n",
    "#     return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fba4adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# n_features, pearsons = zip(*results)\n",
    "# plt.figure()\n",
    "# plt.plot(n_features, pearsons)\n",
    "# plt.xlabel(\"Number of Features\")\n",
    "# plt.ylabel(\"Pearson Correlation\")\n",
    "# plt.title(\"Pearson vs. Number of Top Features\")\n",
    "# plt.grid(True)\n",
    "# # plt.savefig(\"../data/resources/pearson_vs_n_features.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bfdccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model.save_model(f\"../data/lightgbm_top{best_n}_features.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b5dfcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_submission(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef88b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
